Vertex Patition vs. Edge Collapse

  Edge Collapse uses a 'distortion order', which is a inversed removal order. Distortion order changes as the model is simplified, and thus cannot be determined a priori. Given a partitioning of the data, it is highly probable that a change in one partition could cause the order to change in another partition. This is undesirable because we would like for each partition to be independent [Brodsky & Pedersen. Parallel Model Simplification of Very Large Polygonal Meshes]. 
  
Patch Growing

  [Hinker & Hansen. Geometric optimization]
  [Kalvin & Taylor. Superfaces: Polygonal mesh simplification with bounded error]
  [Schroeder, Zarge & Lorensen. Decimation of triangle meshes]
  [Turk. Re-tiling polygonal surfaces]
 
Data paritioning
  Although it is easy to partition the input model, it is more difficult to partition the output model. A cluster represents a primitive in the simplified model. In R-Simp the stopping criteria is the number of clusters N. In a parallel or a serialized parallel algorithm N = N1 + N2 ... + Nn , where Ni is the number of clusters in partition i. It is diffocult to determine Ni because it depends on the surface in the other partitions. There are several ways to approximate Ni but it is not known how to obtain the exact value at the present time. 
  
Loss of Ordering In Patching Simplification (TAKEN FROM [Brodsky & Pedersen. Parallel Model Simplification of Very Large Polygonal Meshes])

  Simplification algorithm simplicitly depend on their simplification steps to be ordered. This ordering is lost when parallelizing a sequential algorithm or enabling it to operate in a limited memory environment. Thereis ordering within each task, but not in between tasks, that is sufficient for PR-Simp and for algorithms such as
  
  [Brodsky & Watson. Model simplification through refinement]
  [Hinker & Hansen. Geometric optimization]
  [Kalvin & Taylor. Superfaces: Polygonal mesh simplification with bounded error]
  [Schroeder, Zarge & Lorensen. Decimation of triangle meshes]
  [Turk. Re-tiling polygonal surfaces]
  
  These algorithms access the data in model or spatial order and thus, the partitions are independent. This independence allows the algorithms to lose the global ordering and still maintain the same level of quality as their sequential counter parts. 
  
  For other algorithmssuch as [QSlim, Progressive Mehse, Fast and Memory Efficient Simplifcation], this loss of total ordering is detrimental to simplificati on quality. In these algorithms, the choice for optimal simplification step (i) depends on the outcome of step (i - 1). Given that this is no longer the case,the end result will be suboptimal.
  
  Increasing the number of patches perturbs the global ordering of the simplification operations. 
 
Relationship between number of patches and the simplification quality (TAKEN FROM [Brodsky & Pedersen. Parallel Model Simplification of Very Large Polygonal Meshes])

  The number of patches does not significantly affect the quality of the simplified model as long as it is large enough. This means that using a large number of processors is possible and feasible. However, the ratio of processors to the number of vertices in the output model should be kept small. 
  
  As model simplification in parallel is virtually impossible without relaxing the ordering of the operations and thus introducing errors, we have still managed to achieve simplified models without jeopardizing the quality of the result significantly. 
  
  As mentioned earlier, the lack of global ordering can negatively effect the quality of the result, but according to the tests we have run, the error does not change significantly if the output model is reasonably large.
  
  If the output model is too small, utilizing a large number of processors can negatively effect the result. When simplifying polygonal models, the rule of thumb can be summarized in the following points: (1) do it sequentially if possible, which will give a better quality of the simplified result, especially if the output model is small, and(2) doit in parallel if the model is too large for the sequential program, or if speed is important. If quality is veryimportant, simplify in parallel until the model can fit in the memory of one processor, and run a sequential algorithm to further simplify the model.
  
Block Size (TAKEN FROM [Prince. Progressive Meshes for Large Models of Arbitrary Topology])

  The main variable in partitioning is the choice of block size. Smaller blocks, which take up less memory, will help reduce the memory footprint of our simplification procedure. In addition, one advantage of smaller, more numerous blocks is that when we are rendering our final mesh, we will be able to load and unload pieces of the mesh at a finer granularity. However, there exists a point at which decreasing the block size is no longer advantageous. This is because we cannot collapse edges on a block¡¯s boundary when we are simplifying that block. So once the blocks are small enough that a significant percentage of their edges lie on the block¡¯s boundary, there is little gain to be had by using smaller blocks.
  
Not simplifying boundary (TAKEN FROM [Prince. Progressive Meshes for Large Models of Arbitrary Topology])
  
  As Hoppe showed for the case of terrain meshes, the overhead imposed by not simplifying boundaries is very low (less than a 1% increase in the number of faces required when rendering). This is because boundaries that are not simplified at one level of the hierarchy will usually be simplified at the next level of the hierarchy, when they have been stitched together with their neighbors. (At that point, many of the edges that were formerly on block boundaries are now in the stitched block¡¯s interior.)
  
